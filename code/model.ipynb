{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bce34cb0",
   "metadata": {},
   "source": [
    "## TensorFlow Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f02b38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f0b756a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Shape: (17400, 25)\n",
      "Spalten: ['Unnamed: 0', 'Engine type_In-line four, four-stroke', 'Engine type_In-line three, four-stroke', 'Engine type_Single cylinder, four-stroke', 'Engine type_Single cylinder, two-stroke', 'Engine type_Twin, four-stroke', 'Engine type_Twin, two-stroke', 'Engine type_Two cylinder boxer, four-stroke', 'Engine type_V2, four-stroke', 'Engine type_V4, four-stroke', 'Transmission type,final drive_Belt', 'Transmission type,final drive_Chain', 'Transmission type,final drive_Shaft drive (cardan)', 'Front brakes_Double disc', 'Front brakes_Dual disc', 'Front brakes_Expanding brake', 'Front brakes_Expanding brake (drum brake)', 'Front brakes_Single disc', 'Rear brakes_Expanding brake', 'Rear brakes_Expanding brake (drum brake)', 'Rear brakes_Single disc', 'Displacement ccm', 'Fuel capacity liters', 'Power HP', 'Category']\n"
     ]
    }
   ],
   "source": [
    "current = current = os.getcwd()\n",
    "parent = parent_dir = os.path.dirname(current)\n",
    "df = pd.read_csv(parent_dir+\"/data/joint_data_collection_8targets.csv\")\n",
    "print(f\"Dataset Shape: {df.shape}\")\n",
    "print(f\"Spalten: {df.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "487fbf23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Features Shape: (17400, 24)\n",
      "Target (Text) Shape: (17400,)\n",
      "Unique Target Values: 8\n",
      "Target Klassen: ['Classic' 'Cross / motocross' 'Naked bike' 'Scooter' 'Sport'\n",
      " 'Super motard' 'Touring' 'Unspecified category']\n",
      "\n",
      "Encoded Target Shape: (17400,)\n",
      "Label Mapping:\n",
      "  0: Classic\n",
      "  1: Cross / motocross\n",
      "  2: Naked bike\n",
      "  3: Scooter\n",
      "  4: Sport\n",
      "  5: Super motard\n",
      "  6: Touring\n",
      "  7: Unspecified category\n",
      "\n",
      "Training Samples: 13920\n",
      "Test Samples: 3480\n"
     ]
    }
   ],
   "source": [
    "target_column = 'Category'  # <-- HIER ANPASSEN!\n",
    "\n",
    "# Features (alle numerischen Spalten) und Target (Text) trennen\n",
    "X = df.drop(target_column, axis=1).values\n",
    "y_text = df[target_column].values\n",
    "\n",
    "print(f\"\\nFeatures Shape: {X.shape}\")\n",
    "print(f\"Target (Text) Shape: {y_text.shape}\")\n",
    "print(f\"Unique Target Values: {len(np.unique(y_text))}\")\n",
    "print(f\"Target Klassen: {np.unique(y_text)}\")\n",
    "\n",
    "# Text-Target zu numerischen Labels konvertieren\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y_text)\n",
    "\n",
    "print(f\"\\nEncoded Target Shape: {y.shape}\")\n",
    "print(f\"Label Mapping:\")\n",
    "for i, label in enumerate(label_encoder.classes_):\n",
    "    print(f\"  {i}: {label}\")\n",
    "\n",
    "num_classes = len(label_encoder.classes_)\n",
    "\n",
    "# Train/Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"\\nTraining Samples: {len(X_train)}\")\n",
    "print(f\"Test Samples: {len(X_test)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38b3e25",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53dd305e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "MODEL ARCHITEKTUR\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\AIBAS HA\\Repo\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:106: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,800</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,104</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │        \u001b[38;5;34m12,800\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │         \u001b[38;5;34m2,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m262,656\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │         \u001b[38;5;34m2,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m262,656\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │         \u001b[38;5;34m2,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m262,656\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │         \u001b[38;5;34m4,104\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">811,016</span> (3.09 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m811,016\u001b[0m (3.09 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">807,944</span> (3.08 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m807,944\u001b[0m (3.08 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,072</span> (12.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m3,072\u001b[0m (12.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(512, activation='softmax', input_shape=(X_train.shape[1],)),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    \n",
    "    keras.layers.Dense(512, activation='softmax'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    \n",
    "    keras.layers.Dense(512, activation='softmax'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    \n",
    "    keras.layers.Dense(512, activation='softmax'),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    \n",
    "    keras.layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Model Summary\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MODEL ARCHITEKTUR\")\n",
    "print(\"=\"*60)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0341bdd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotTrainingAndValidationPerformance(epochs, accuracy, val_accuracy, loss, val_loss):\n",
    "    \"\"\"\n",
    "    This function creates and stores the (1) accuracy plot and (2) loss plot\n",
    "    for training and validation performances and stores them as (a) png and (b) pdf file\n",
    "    at the 'learningBase' of docker volume 'ai_system'.\n",
    "    - loss: categorical_crossentropy\n",
    "    Computes the crossentropy loss between the labels and predictions.\n",
    "    This loss is the crossentropy metric class to be used when there are multiple label classes (2 or more). \n",
    "    Here it is assumed that labels are given as a `one_hot` representation. \n",
    "    For instance, when `labels` are [2, 0, 1], `y_true` = [[0, 0, 1], [1, 0, 0], [0, 1, 0]].\n",
    "    remember: a lower validation loss indicates a better model.\n",
    "    - accuracy: \n",
    "    This metric creates two local variables, `total` and `count` \n",
    "    that are used to compute the frequency with which `y_pred` matches `y_true`. \n",
    "    This frequency is ultimately returned as `binary accuracy`: an idempotent operation that simply divides `total` by `count`.\n",
    "    remember: a higher validation accuracy indicates a better model.\n",
    "    \"\"\"\n",
    "    \n",
    "    # initialize figure\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    \n",
    "    # characterize accuracy plot\n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.plot(epochs, accuracy, label=\"Training Accuracy\")\n",
    "    plt.plot(epochs, val_accuracy, label=\"Validation Accuracy\")\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.title(\"Training and Validation Accuracy\")\n",
    "    \n",
    "    # characterize loss plot\n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.plot(epochs, loss, label=\"Training Loss\")\n",
    "    plt.plot(epochs, val_loss, label=\"Validation Loss\")\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.title(\"Training and Validation Loss\")\n",
    "    \n",
    "    # indicate performance by showing plot generated (having displays connected)\n",
    "    #plt.show()\n",
    "    \n",
    "    # indicate performance by storing the plot as png and pdf file\n",
    "    plt.savefig('TrainingPerformance.png')\n",
    "    plt.savefig('TrainingPerformance.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c334e30d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TRAINING STARTED\n",
      "============================================================\n",
      "Epoch 1/3000\n"
     ]
    }
   ],
   "source": [
    "epochen=3000\n",
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=100,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1,\n",
    "        min_delta=0.0001\n",
    "    ),\n",
    "    keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=10,\n",
    "        min_lr=1e-7,\n",
    "        verbose=1,\n",
    "        min_delta=0.0001\n",
    "    )\n",
    "   \n",
    "]\n",
    "\n",
    "# Training starten\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"TRAINING STARTED\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "start_time = datetime.now()\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=epochen,\n",
    "    batch_size=256,\n",
    "    validation_split=0.2,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "#callbacks=callbacks,\n",
    "end_time = datetime.now()\n",
    "training_duration = (end_time - start_time).total_seconds()\n",
    "\n",
    "# Training Metriken extrahieren\n",
    "final_epoch = len(history.history['loss'])\n",
    "final_train_loss = history.history['loss'][-1]\n",
    "final_train_accuracy = history.history['accuracy'][-1]\n",
    "final_val_loss = history.history['val_loss'][-1]\n",
    "final_val_accuracy = history.history['val_accuracy'][-1]\n",
    "\n",
    "# Best Epoch finden\n",
    "best_epoch = np.argmin(history.history['val_loss']) + 1\n",
    "best_val_loss = np.min(history.history['val_loss'])\n",
    "best_val_accuracy = history.history['val_accuracy'][best_epoch - 1]\n",
    "\n",
    "# Training Summary ausgeben\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"TRAINING SUMMARY\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Total Training Iterations (Epochs): {final_epoch}\")\n",
    "print(f\"Training Duration: {training_duration:.2f} seconds ({training_duration/60:.2f} minutes)\")\n",
    "print(f\"\\nFinal Epoch ({final_epoch}):\")\n",
    "print(f\"  - Training Loss: {final_train_loss:.6f}\")\n",
    "print(f\"  - Training Accuracy: {final_train_accuracy:.6f} ({final_train_accuracy*100:.2f}%)\")\n",
    "print(f\"  - Validation Loss: {final_val_loss:.6f}\")\n",
    "print(f\"  - Validation Accuracy: {final_val_accuracy:.6f} ({final_val_accuracy*100:.2f}%)\")\n",
    "print(f\"\\nBest Epoch ({best_epoch}):\")\n",
    "print(f\"  - Validation Loss: {best_val_loss:.6f}\")\n",
    "print(f\"  - Validation Accuracy: {best_val_accuracy:.6f} ({best_val_accuracy*100:.2f}%)\")\n",
    "\n",
    "# Test Set Evaluation\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"TEST SET EVALUATION\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Test Loss: {test_loss:.6f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.6f} ({test_accuracy*100:.2f}%)\")\n",
    "\n",
    "# Predictions\n",
    "y_pred_probs = model.predict(X_test, verbose=0)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "# Zurück zu Text-Labels\n",
    "y_test_text = label_encoder.inverse_transform(y_test)\n",
    "y_pred_text = label_encoder.inverse_transform(y_pred)\n",
    "plotTrainingAndValidationPerformance(range(epochen), history.history[\"accuracy\"], history.history[\"val_accuracy\"],history.history[\"loss\"], history.history[\"val_loss\"])\n",
    "model.save(\"/models/bestmodel.h5\", save_format=\"h5\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbdfeec6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
